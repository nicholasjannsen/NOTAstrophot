#!/usr/bin/env python3
# -*- coding: utf-8 -*
"""
Written November 2020 -- Nicholas Jannsen
Typeset in Python 3

This function needs to be called from a terminal (see README file):
chmod +x notastrophot
notastrophot [-p] [-r] [-s] [-c <clip>] <path/to/data/>
"""
#--------------------
#     PACKAGES      :
#--------------------
# Numpy:
import numpy as np
# Matplotlib:
import matplotlib.pyplot as plt
# Astropy:
from astropy.io import fits
from astropy.time import Time
# SciPy:
import scipy
import scipy.ndimage as ndimage
import scipy.ndimage as snd
# skimage:
from skimage import feature as skfeature
from skimage.util import img_as_float32
# Print colors:
from colorama import Fore, Style, Back
# Astroalign:
import astroalign
# Others:
import math, sys, time, glob, pylab, heapq, getopt, os
#--------------------
#     SETTINGS      :
#--------------------
# Global settings for out-print to terminal (allow more digits and nice coloum ordering):
np.set_printoptions(suppress=True, formatter={'float_kind':'{:7.5f}'.format}, linewidth=100)

####################################################################################################
#                                         DEFINE CLASS                                             #
####################################################################################################

class NOTAstrophot(object):

    # INITILIZE THE CLASS:
    def __init__(self, plot, redo, skip, clip, path):
        #--------------------------------------
        # GLOBAL VARIABLES THAT CAN BE TWEAKED:
        #--------------------------------------
        self.borders   = [300,1900,300,1900] # Cut out filter borders of square filters
        self.sigfrac   = 0.05                # Fractional detection limit for neighbouring pixels (0.05)
        self.objlim    = 0.5                 # Contrast limit between CR and underlying object (default 0.5)
        self.maxiter   = 3                   # Max iterations for L.A. cosmic (default 3)
        self.starsigma = 2                   # Star detection threshold in standard deviations
        self.pixshift  = 20                  # Pixel distance for image alignment (default 30)
        self.pathc     = None                # Customize path to calibs or keep default 
        #-----------------------------------
        # GLOBAL VARIABLES - DO NOT CHANGE!:
        #-----------------------------------
        self.plot = plot
        self.redo = redo
        self.skip = skip
        self.sigclip = float(clip)
        self.path = path
        # Sepearte plot options:
        if plot==True:  self.plot = [True,  True,  True,  True ]
        if plot==False: self.plot = [False, False, False, False]
        # Check for correct parsing of plot:
        if len(self.plot)!=4:
            print(Fore.RED+Style.BRIGHT+'ERROR! Plot option takes only 1 or 4 parameters as input')
            sys.exit()
        
        # LOAD OBJECT IMAGE FILES:
        self.h        = self.borders[1]-self.borders[0]  # Image heigh
        self.w        = self.borders[3]-self.borders[2]  # Image width 
        self.LF_files = np.sort(glob.glob('{}AL*'.format(self.path)))
        self.LF_hduls = np.array([fits.open(str(files)) for files in self.LF_files])
        self.LF_n     = len(self.LF_files)
        self.LF_dex   = range(self.LF_n)
        # Check if there are any files:
        if self.LF_files is []:
            print(Fore.RED+'ERROR! No image files available, please check "/path/to/data/"'); sys.exit()

        # EXTRACT FITS HEADERS:
        def LF_headers(name):
            return [self.LF_hduls[i][0].header['{}'.format(name)] for i in range(len(self.LF_files))]
        self.filename = [LF_headers('FILENAME')[i][:10] for i in range(self.LF_n)] 
        self.notdate  = [LF_headers('FILENAME')[i][:6]  for i in range(self.LF_n)]
        self.exptime  = LF_headers('EXPTIME')     
        self.imgtype  = LF_headers('IMAGETYP')
        self.tcstgt   = LF_headers('TCSTGT')
        self.airmass  = LF_headers('AIRMASS')
        # Check and correct old header info:        
        for i in range(self.LF_n):
            if self.imgtype[i]=='': self.imgtype[i] = 'OBJECT'
            if self.imgtype[i]=='OBJECT' and self.tcstgt[i]=='Undefined': self.imgtype[i] = 'FLAT'
        # Check if calibs are place in the same folder:
        if self.imgtype != list(['OBJECT']*self.LF_n):
            print(Fore.RED+Style.BRIGHT+\
                  'ERROR! Calib frames most be placed in the following folder "/path/to/data/../calibs/"')
            sys.exit()
        # Check if object are observed at high airmass':
        if self.airmass > [2.5]*self.LF_n:
            print(Fore.YELLOW+Style.BRIGHT+\
                  'WARNING! One or several frames are observed at Airmass > 2.5 (Altitude < 22 deg)'+\
                  Style.RESET_ALL)
        # Save target name:
        self.dex_target = np.where(np.array(self.imgtype)=='OBJECT')[0]
        self.n_target   = len(self.dex_target)
        self.target     = LF_headers('OBJECT')[self.dex_target[0]]
        # Coordinates of images:
        self.wx = [LF_headers('RA')[self.dex_target[i]]  for i in range(self.n_target)]
        self.wy = [LF_headers('DEC')[self.dex_target[i]] for i in range(self.n_target)]
            
        # FIND FILTER FOR OBJECT IMAGES:
        LF_filt_type_alfosc = np.array([self.LF_hduls[i][0].header['ALFLTNM'] for i in self.LF_dex])
        LF_filt_type_fasua  = np.array([self.LF_hduls[i][0].header['FAFLTNM'] for i in self.LF_dex])
        LF_filt_type_fasub  = np.array([self.LF_hduls[i][0].header['FBFLTNM'] for i in self.LF_dex])
        # Add all filters:
        LF_filt = np.char.add(LF_filt_type_alfosc, LF_filt_type_fasua)
        LF_filt = np.char.add(LF_filt, LF_filt_type_fasub)
        # Correct to right filter (OBS the order here is very specific!):
        self.old_filter_names = ['OpenOpenOpen','Open', ' ', 'IAC040', 'IAC041', '__', "'", '[', ']']
        self.new_filter_names = ['Clear', '', '_', 'Halp_IAC040', 'NII_IAC041', '_', "", '', '']
        for i in range(len(LF_filt)):
            for j in range(len(self.old_filter_names)):
                LF_filt[i] = str(LF_filt[i]).replace(self.old_filter_names[j], self.new_filter_names[j])
        self.LF_filt = LF_filt
        # Special care is needed for narrowband filters:
        self.narrowbands = {'Halp_658_18', 'Halp_656_3', 'Halp_IAC040', \
                            'Hbet_485_13', 'OIII_501_3', 'SII_672_5', \
                            'NII_575_3', 'NII_IAC041'}
        
        # FIND DATES OF OBSERVATIONS AND REDUCE IMAGES FOR ONE DATE AT A TIME:
        self.dates = np.unique(self.notdate)
        
        # DEBUGGING:
        # print(self.imgtype)
        # print(self.tcstgt)
        # sys.exit()
        
    #============================================================================================#
    #                                      IMAGE REDUCTION                                       #
    #============================================================================================#

    def image_reduction(self):
        """
        This function performs image reduction. It takes the directory path as input and load all
        image files. Using the fits header all object and calibration images (bias' and flats) are
        loaded from each day available. Each image type are seperated, as well as each filter, by 
        indices. The software saves fully calibrated light frames ("calib_<notdate>_<filter>") and 
        a master bias ("bias_<notdate>") and master flats ("flats_<notdate>"), respectively.
        ----------------------------
                   OUTPUT          :
        ----------------------------
        MasterBias*.fits     (fits): Master bias frame
        MasterFlat*.fits     (fits): Master flat frames
        calib*.fits          (fits): Calibrated light frames
        """
        # FUNCTION EXTRACT FITS HEADERS:
        def LF_headers(name):
            return [LF_hduls[i][0].header['{}'.format(name)] for i in range(len(LF_files))]

        #-------------------------
        # PERFORM IMAGE REDUCTION:
        #-------------------------

        # LOOP OVER EACH DATE:
        for i in range(len(self.dates)):
            
            #--------------------------------
            # LOAD ALL INFO FOR LIGHT FRAMES:
            #--------------------------------

            # LOAD IMAGE FILES:
            LF_files = np.sort(glob.glob('{}{}*.fits'.format(self.path, self.dates[i])))
            LF_hduls = np.array([fits.open(str(files)) for files in LF_files])
            LF_n     = len(LF_files)
            LF_dex   = range(LF_n)

            # EXTRACT FITS HEADERS:
            LF_filename = [LF_headers('FILENAME')[i][:10] for i in range(len(LF_files))] 

            # FIND OBJECT FILTERS:
            LF_filt_type_alfosc = np.array([LF_hduls[i][0].header['ALFLTNM'] for i in LF_dex])
            LF_filt_type_fasua  = np.array([LF_hduls[i][0].header['FAFLTNM'] for i in LF_dex])
            LF_filt_type_fasub  = np.array([LF_hduls[i][0].header['FBFLTNM'] for i in LF_dex])
            # Add all filters:
            LF_filt = np.char.add(LF_filt_type_alfosc, LF_filt_type_fasua)
            LF_filt = np.char.add(LF_filt, LF_filt_type_fasub)
            # Correct to right filter (OBS the order here is very specific!):
            for n in range(len(LF_filt)):
                for j in range(len(self.old_filter_names)):
                    LF_filt[n] =str(LF_filt[n]).replace(self.old_filter_names[j],self.new_filter_names[j])
                    
            #--------------------------------
            # LOAD ALL INFO FOR CALIB FRAMES:
            #--------------------------------

            # LOAD IMAGE FILES:
            if self.pathc is None: pathc = self.path+'../calibs/'+self.dates[i]+'/'
            calib_files = np.sort(glob.glob('{}AL*.fits'.format(pathc)))
            calib_hduls = np.array([fits.open(str(files)) for files in calib_files])
            
            # EXTRACT CALIBS HEADER INFO:
            def headers(name):
                return [calib_hduls[i][0].header['{}'.format(name)] for i in range(len(calib_files))]
            filename = [headers('FILENAME')[i][:10] for i in range(len(calib_files))]
            notdate  = [headers('FILENAME')[i][:6]  for i in range(len(calib_files))]
            imgtype  = headers('IMAGETYP')
            datetime = [headers('DATE-OBS')[i]  for i in range(len(calib_files))]
            
            # BIAS FRAMES:
            BF_dex = np.where(np.array(imgtype)=='BIAS')[0]
            if not BF_dex.any():
                print(Fore.RED+Style.BRIGHT+\
                      'ERROR: Missing bias images for date {}!'.format(self.dates[i])); sys.exit()
            else:    
                # Load calib-images into arrays:
                BF_i = np.array([fits.getdata(str(calib_files[i])) for i in BF_dex])
                # Cut out the borders of the square filters:
                BF_i = BF_i[:, self.borders[0]:self.borders[1], self.borders[2]:self.borders[3]]

            # FLATS FRAMES:
            FF_sky_dex  = np.where(np.array(imgtype)=='FLAT,SKY')[0]
            FF_dome_dex = np.where(np.array(imgtype)=='FLAT')[0]
            FF_dex      = np.append(FF_dome_dex, FF_sky_dex)
            # Check if images exist:
            if not FF_dex.any():
                print(Fore.RED+Style.BRIGHT+\
                      'ERROR: Missing flat images for date {}!'.format(self.dates[i]));sys.exit()
            else:
                # FIND FLAT FILTERS:
                FF_filt_type_alfosc = np.array([calib_hduls[i][0].header['ALFLTNM'] for i in FF_dex])
                FF_filt_type_fasua  = np.array([calib_hduls[i][0].header['FAFLTNM'] for i in FF_dex])
                FF_filt_type_fasub  = np.array([calib_hduls[i][0].header['FBFLTNM'] for i in FF_dex])
                # Add all filters:
                FF_filt = np.char.add(FF_filt_type_alfosc, FF_filt_type_fasua)
                FF_filt = np.char.add(FF_filt, FF_filt_type_fasub)
                for m in range(len(FF_filt)):
                    for k in range(len(self.old_filter_names)):
                        FF_filt[m] = str(FF_filt[m]).replace(self.old_filter_names[k], \
                                                             self.new_filter_names[k])
                        # Find index of same flats and index of flats filter corresp. to light frames:
                        FF_dif      = np.unique(FF_filt)
                        FF_filt_dif = np.array([np.where(FF_filt==FF_dif[i])[0] \
                                                for i in range(len(FF_dif))])
                        FF_filt_dex = np.array([np.where(FF_dif==self.LF_filt[i])[0] \
                                                for i in range(len(self.LF_dex))])
               
                # # Load calib-images into arrays: 
                FF_i = np.array([fits.getdata(str(calib_files[i])) for i in FF_dex])
                # Cut out the borders of the square filters:
                FF_i = FF_i[:, self.borders[0]:self.borders[1], self.borders[2]:self.borders[3]]

                # DEBUGGING:
                # print(FF_dif)
                # print(FF_filt_dif)
                # print(FF_filt_dex)
                # sys.exit()
                
            #--------------------------------
            # MAKE MASTER CALIBRATION FRAMES:
            #--------------------------------

            # MAKE MASTER BIAS:
            BF = np.median(BF_i, axis=0)
            # Find bias level:
            BF_med = np.median(BF)
            # Save master bias:
            fits.writeto('{}MasterBias_{}.fits'.format(pathc, self.notdate[i]), \
                         BF, header=calib_hduls[BF_dex[0]][0].header, overwrite=True)

            # MAKE MASTER FLATS:
            if self.skip==False:
                FF_k = np.zeros((len(FF_filt_dif), self.h, self.w))
                # Loop over each filter
                for k in range(len(FF_filt_dif)):             
                    FF_j = np.array([FF_i[j] for j in FF_filt_dif[k]])
                    # Different cases if bias exist or not:
                    FF = np.median(FF_j - BF, axis=0)
                    # If negative pixel values:
                    FF[FF<=0] = np.median(FF)
                    # Normalization and store:
                    FF = FF/np.max(FF)
                    FF_k[k] = FF
                # Save master flats:    
                for j in range(len(FF_k)):
                    fits.writeto('{}/MasterFlat_{}_{}.fits'.format(pathc, self.dates[i], \
                                                                      FF_dif[j]), FF_k[j], \
                                 header=calib_hduls[FF_filt_dif[j][0]][0].header, overwrite=True)

            #---------------------
            # PERFORM CALIBRATION:
            #---------------------

            # Find index of flats filter corresponding to the light frames:
            for j in LF_dex:
                # Open and close and singel image at a time:
                with fits.open(str(LF_files[LF_dex[j]])) as hdu_j:
                    LF_j = hdu_j[1].data
                    # Cut out image if ALFOSC images:
                    LF_j = LF_j[self.borders[0]:self.borders[1], self.borders[2]:self.borders[3]]
                    # Subtract bias to remove extreme outliers:
                    LF = LF_j - BF
                    # Divide by flat:
                    if self.skip!=1:
                        k  = FF_filt_dex[j]
                        CF = LF/FF_k[k][0]
                        # NARROW BAND FILTERS NEED SPECIAL CARE:
                        if LF_filt[j] in self.narrowbands:
                            # Mask cornors and replace by Gaussian background:
                            mask_edges = np.copy(LF_j)
                            mask_edges[np.where(mask_edges<=BF_med)] = 1
                            mask_edges[np.where(mask_edges!=1)] = 0
                            mask_edges[np.where(mask_edges==1)] = 8/9*np.median(CF)
                            # Mask image center of reduced image:
                            mask_image = np.copy(LF_j)
                            mask_image[np.where(mask_image>=BF_med)] = 1
                            mask_image[np.where(mask_image!=1)] = 0
                            mask_image = mask_image * CF
                            # New image:
                            CF = mask_edges + mask_image                    
                    else:
                        CF = LF

                    # SAVE IMAGES:
                    fits.writeto('{}calib_{}_{}.fits'.format(self.path, LF_filename[LF_dex[j]], \
                                                             LF_filt[j]),\
                                 CF, header=LF_hduls[LF_dex[j]][0].header, overwrite=True)

                    # PLOT BEFORE AND AFTER:
                    if self.plot[0] is True:
                        self.FITS_calib(LF, CF, self.dates[i], LF_filt[j])

                # Print to bash:
                self.compilation(j, LF_n, self.dates[i])
            print; print('')

            # EXIT LOOP IF ONLY ONE DATE IS PRESENT:
            if len(self.dates)==1: break
            
    #============================================================================================#
    #                                        COSMIC REMOVAL                                      #
    #============================================================================================#

    def cosmic_removal(self):
        """
        This functions is a python module to detect and clean cosmic ray hits on images (numpy
        arrays or fits) using scipy, and based on Pieter van Dokkum's L.A.Cosmic algorithm. The
        software also automatic recognition of saturated stars, and including their full saturation
        trails. This avoids that such stars are treated as big cosmics. Indeed saturated stars tend
        to get even uglier when you try to clean them, plus they keep L.A.Cosmic iterations going
        on forever. This feature is mainly for pretty-image production. Scipy image analysis allows
        to "label" the actual cosmic ray hits (i.e. group the pixels into local islands). Otherwise 
        the core is really a 1-to-1 implementation of L.A.Cosmic, and uses the same parameters. Only
        the conventions on how filters are applied at the image edges might be different. No surprise,
        this python module is much faster then the IRAF implementation, as it does not read/write
        every step to disk. Author: 
        """
        # COSMICS LIMITS:
        self.sigcliplow = self.sigclip * self.sigfrac
        self.backgroundlevel = None
        self.gain     = 2.2     # gain (electrons/ADU)
        self.ron      = 11329.0
        self.satlevel = 6e5  # Saturation level of CCD3 ALFOSC (ADU/pixel)

        # Load reduceed images:
        imgfiles = np.sort(glob.glob('{}calib*'.format(self.path)))
        hdu_i    = np.array([fits.open(str(files)) for files in imgfiles])

        # Loop over each object frame:
        for i in range(self.LF_n):
            
            # LOAD IMAGES AND AVOID STRANGE VALUES:
            img = hdu_i[i][0].data
            img[img<0] = 0                          # Avoid too low counts
            #img[img>self.satlevel] = self.satlevel  # Avoid too high counts
            
            # SEPERATE INTO ARRAYS:
            self.rawarray   = img + 0.0
            self.cleanarray = self.rawarray.copy() # In lacosmiciteration() we work on this guy
            self.mask       = np.cast['bool'](np.zeros(self.rawarray.shape)) # All False, no cosmics yet
            
            # FIND SATURATED STARS:
            self.mask_saturated_stars()
            
            # START L.A.COSMIC ITERATIONS:
            for j in range(1, self.maxiter): # Max iter			
                iterres = self.lacosmic_iteration()
                # Thus we always apply it on the full mask, as lacosmic does:
                self.clean()
                # Do not continue if no new cosmics are found:
                if iterres["niter"] == 0: break

            # SAVE EACH SCIENCE IMAGE:
            fits.writeto('{}clean_{}_{}.fits'.format(self.path,self.filename[self.LF_dex[i]], \
                                                     self.LF_filt[i]), self.cleanarray, \
                         header=self.LF_hduls[self.LF_dex[i]][0].header, overwrite=True)
                
            # PLOT EACH RESULT:
            if self.plot[1] is True:
                self.FITS_clean(self.rawarray, self.cleanarray, self.notdate[i], self.LF_filt[i], self.mask)
        
            # Print to bash:
            self.compilation(i, self.LF_n, 'Reduced')
        print; print('')
                    

    def mask_saturated_stars(self):
        """
        This subroutine finds and masks saturated stars using the saturation level of the CCD.
        """
        #-----------
        # DETECTION:
        #-----------
	# the candidate pixels
        satpixels = self.rawarray >= self.satlevel/2.0
        # We build a smoothed version of the image to look for large stars and their support:
        m5 = scipy.ndimage.filters.median_filter(self.rawarray, size=5, mode='mirror')
        
	# We look where this is above half the satlevel:
        largestruct = m5 > (self.satlevel/10.0)
        # The rough locations of saturated stars are now:
        satstarscenters = np.logical_and(largestruct, satpixels)
        #-------------------
        # BUILDING THE MASK:
        #-------------------
        # We dilate the satpixels alone, to ensure connectivity in glitchy regions and to add
        # a safety margin around them. It turns out it's better to think large and do 2 iterations...
        dilstruct    = np.array([[0,1,0], [1,1,1], [0,1,0]])
        dilsatpixels = ndimage.morphology.binary_dilation(largestruct, structure=dilstruct, iterations=2, \
                                                          mask=None, output=None, border_value=0, \
                                                          origin=0, brute_force=False)
        # We label these:
        (dilsatlabels, nsat) = ndimage.measurements.label(dilsatpixels) 
        # The ouput, False for now:
        outmask = np.zeros(self.rawarray.shape)
        # We go through the islands of saturated pixels
        for i in range(1,nsat+1):
            # gives us a boolean array
            thisisland = dilsatlabels == i
	    # Does this intersect with satstarscenters ?
            overlap = np.logical_and(thisisland, satstarscenters)
            if np.sum(overlap) > 0:
                outmask = np.logical_or(outmask, thisisland) # we add thisisland to the mask
	# Save the mask 'satstars': 
        self.satstars = np.cast['bool'](outmask)
	

    def lacosmic_iteration(self):
        """
        Performs one iteration of the L.A.Cosmic algorithm. It operates on self.cleanarray, 
        and afterwards updates self.mask by adding the newly detected cosmics to the existing
        self.mask. Cleaning is not made automatically. You have to call 'clean()' after each
        iteration. This way you can run it several times in a row to to L.A.Cosmic "iterations".
        See function lacosmic, that mimics the full iterative L.A.Cosmic algorithm. Returns a
        dict containing:
	- niter : the number of cosmic pixels detected in this iteration
	- nnew : among these, how many were not yet in the mask
	- itermask : the mask of pixels detected in this iteration
	- newmask : the pixels detected that were not yet in the mask
	If 'find_saturated_stars()' was called, we exclude these regions from the search.
	"""
        #----------------------------------------
        # CONVOLVING IMAGE WITH LAPLACIAN KERNEL:
        #----------------------------------------
        # Make a LaPlacian kernel:
        laplkernel = np.array([[0.0, -1.0, 0.0], [-1.0, 4.0, -1.0], [0.0, -1.0, 0.0]])
        # We subsample, convolve, clip negative values, and rebin to original size
        subsam = self.subsample(self.cleanarray)
        conved = scipy.signal.convolve2d(subsam, laplkernel, mode="same", boundary="symm")
        cliped = conved.clip(min=0.0)
        lplus = self.rebin2x2(cliped)
        #----------------------
        # CREATING NOISE MODEL:
        #----------------------
        # We build a custom noise map, so to compare the laplacian to
        m5 = scipy.ndimage.filters.median_filter(self.cleanarray, size=5, mode='mirror')
        # We keep this m5, as I will use it later for the interpolation.
        m5clipped = m5.clip(min=0.00001) # As we will take the sqrt
        noise = (1.0/self.gain) * np.sqrt(self.gain*m5clipped + self.ron**2)
        # Laplacian signal to noise ratio (the 2.0 is from the 2x2 subsampling):
        # This s is called sigmap in the original lacosmic.cl
        s = lplus / (2.0 * noise) 
        # We remove the large structures (s prime) :
        sp = s - scipy.ndimage.filters.median_filter(s, size=5, mode='mirror')
 	#----------------------------------
        # SELECTING CANDIDATES FOR COSMICS:
        #----------------------------------
        # Candidate cosmic rays (this will include stars + HII regions)
        candidates = sp > self.sigclip	
        nbcandidates = np.sum(candidates)
        # At this stage we use the saturated stars to mask the candidates, if available :
        if self.satstars is not None:
            candidates = np.logical_and(np.logical_not(self.satstars), candidates)
            nbcandidates = np.sum(candidates)
	#-------------------------------
        # BUILDING FINE STRUCTURE IMAGE:
        #-------------------------------
        # In the article that's it, but in lacosmic.cl f is divided by the noise...
        # Ok I understand why, it depends on if you use sp/f or L+/f as criterion.
        # There are some differences between the article and the iraf implementation.
        m3  = scipy.ndimage.filters.median_filter(self.cleanarray, size=3, mode='mirror')
        m37 = scipy.ndimage.filters.median_filter(m3, size=7, mode='mirror')
        f   = m3 - m37
        # So I will stick to the iraf implementation.
        f = f / noise
        f = f.clip(min=0.01) # as we will divide by f. like in the iraf version.
	#------------------------------------
        # REMOVING SUSPECTED COMPACT OBJECTS:
        #------------------------------------
        # Now we have our better selection of cosmics :
        cosmics = np.logical_and(candidates, sp/f > self.objlim)
        # Note the sp/f and not lplus/f ... due to the f = f/noise above.	
        nbcosmics = np.sum(cosmics)
        #----------------------------------------------------
        # FINDING NEIGHBORING PIXELS AFFECTED BY COSMIC RAYS:
        #----------------------------------------------------
        # What follows is a special treatment for neighbors, with more relaxed constains.
        growkernel = np.ones((3,3))
        growcosmics = np.cast['bool'](scipy.signal.convolve2d(np.cast['float32'](cosmics), growkernel, \
                                                              mode="same", boundary="symm"))
        # From this grown set, we keep those that have sp > sigmalim
        # so obviously not requiring sp/f > objlim, otherwise it would be pointless
        growcosmics = np.logical_and(sp > self.sigclip, growcosmics)	
        # Now we repeat this procedure, but lower the detection limit to sigmalimlow
        finalsel = np.cast['bool'](scipy.signal.convolve2d(np.cast['float32'](growcosmics), growkernel, \
                                                           mode="same", boundary="symm"))
        finalsel = np.logical_and(sp > self.sigcliplow, finalsel)
        # Again, we have to kick out pixels on saturated stars :
        if self.satstars is not None:
            finalsel = np.logical_and(np.logical_not(self.satstars), finalsel)
        nbfinal = np.sum(finalsel)
        # Now the replacement of the cosmics. We outsource this to the function clean, as for
        # some purposes the cleaning might not even be needed.
        # We find how many cosmics are not yet known :
        newmask = np.logical_and(np.logical_not(self.mask), finalsel)
        nbnew = np.sum(newmask)	
        # We update the mask with the cosmics we have found :
        self.mask = np.logical_or(self.mask, finalsel)
        # We return (used by function lacosmic)
        return {"niter":nbfinal, "nnew":nbnew, "itermask":finalsel, "newmask":newmask}


    def clean(self):
        """
        Given the mask, we replace the actual problematic pixels with the masked 5x5 median value.
        This mimics what is done in L.A.Cosmic, but it's a bit harder to do in python, as there is 
        no readymade masked median, hence for now we do a loop. Saturated stars, if calculated, are
        also masked: they are not "cleaned", but their pixels are not used for the interpolation.	
	We will directly change self.cleanimage. Instead of using the self.mask, you can supply your
	own mask as argument. This might be useful to apply this cleaning function iteratively.
	But for the true L.A.Cosmic, we don't use this, i.e. we use the full mask at each iteration.
        """
        # So 'mask' is a 2D array containing False and True, where True means "here is a cosmic"
        # We want to loop through these cosmics one by one.
        # This is a list of the indices of cosmic affected pixels:
        cosmicindices = np.argwhere(self.mask)
        # We put cosmic ray pixels to np.Inf to flag them:
        self.cleanarray[self.mask] = np.Inf
        # Now we want to have a 2 pixel frame of Inf padding around our image.
        w = self.cleanarray.shape[0]
        h = self.cleanarray.shape[1]
        padarray = np.zeros((w+4,h+4)) + np.Inf
        # The following 'copy' is important, as 2 independent arrays are needed:
        padarray[2:w+2,2:h+2] = self.cleanarray.copy() 
        # The medians will be evaluated in this padarray, skipping the np.Inf.
        # Now in this copy called padarray, we also put the saturated stars to np.Inf, if available:
        # if self.satstars is not None:
        #     padarray[2:w+2,2:h+2][self.satstars] = np.Inf
        # A loop through every cosmic pixel:
        for cosmicpos in cosmicindices:
            x = cosmicpos[0]
            y = cosmicpos[1]
            # Remember the shift due to the padding!
            cutout = padarray[x:x+5, y:y+5].ravel() 
            # Now we have our 25 pixels, some of them are np.Inf, and we want to take the median
            goodcutout = cutout[cutout != np.Inf]
            # This never happened, but you never know ...
            if np.alen(goodcutout) >= 25:
                print('ERROR in clean!'); sys.exit()
            # Normal cases for cosics:
            elif np.alen(goodcutout) > 0:
                replacementvalue = np.median(goodcutout)
            # i.e. no good pixels : Shit, a huge cosmic, we will have to improvise ...
            else:
                replacementvalue = self.guessbackgroundlevel()
            # We update the cleanarray, but measure the medians in the padarray, so to not mix things up...
            self.cleanarray[x, y] = replacementvalue
    
    #--------------------------------------------------------------------------------------------------
    # These are more generic functions than methods ...
    
    def subsample(self, a): 
        """
        Returns a 2x2-subsampled version of array a (no interpolation, just cutting pixels in 4).
        The version below is directly from the scipy cookbook on rebinning:
        U{http://www.scipy.org/Cookbook/Rebinning}
        There is ndimage.zoom(cutout.array, 2, order=0, prefilter=False), but it makes funny borders.
	"""
        newshape = (2*a.shape[0], 2*a.shape[1])
        slices = [slice(0,old, float(old)/new) for old,new in zip(a.shape,newshape) ]
        coordinates = np.mgrid[slices]
        indices = coordinates.astype('i')   #choose the biggest smaller integer index
        return a[tuple(indices)]

    def rebin2x2(self, a):
        """
        Wrapper around rebin that actually rebins 2 by 2
        """
        inshape = np.array(a.shape)
        if not (inshape % 2 == np.zeros(2)).all(): # Modulo check to see if size is even
           print("OBS: Image do not have integer dimensions!")	
        return self.rebin(a, inshape/2)

    def rebin(self, a, shape):
        """
        General rebin function
        """
        sh = int(shape[0]), int(a.shape[0]//shape[0]), int(shape[1]), int(a.shape[1]//shape[1])
        newshape = a.reshape(sh).mean(-1).mean(1)
        return newshape

    def guessbackgroundlevel(self):
        """
        Estimates the background level. This could be used to fill pixels in large cosmics.
        """
        if self.backgroundlevel == None:
            self.backgroundlevel = np.median(self.rawarray.ravel())
        return self.backgroundlevel

    def find_structures(self, mask):
        # Label the structures:
        labels, nlabels = snd.label(mask*1, structure = np.ones((3,3)))
        # Sum the number of elements in each structure:
        sums   = snd.sum(mask*1, labels, range(1,nlabels+1))
        # Radius and center-of-flux for each structure:
        radius = np.sqrt(sums**2/np.pi)
        COF    = np.asarray(snd.center_of_mass(mask*1, labels, range(1,nlabels+1)))
        return radius, COF

    #============================================================================================#
    #                                       IMAGE ALIGNMENT                                      #
    #============================================================================================#

    def image_alignment(self): 
        """
        This function takes N number of frames and align them, thus make the post processing easier.
        This function can both shift frames using stellar centroids.
        """
        # LOAD DATA:
        img_files = np.sort(glob.glob('{}clean*'.format(self.path)))
                      
        # Loop over all files:
        for i in range(self.LF_n):

            # Make string to save files:
            string_i = str(img_files[i]).replace('clean', 'imreg')

            # Open and close each file in order not to overload buffer:
            with fits.open(str(img_files[i])) as hduls:

                # Load image (float32 specific for skimage.wrap inside astroalign)
                img_i = img_as_float32(hduls[0].data)

                # Use the 0th image as reference:
                if i is 0: img_ref = img_i
                
                # FIRST TRY ASTROALIGN: (https://github.com/toros-astro/astroalign)
                try: img_reg, _ = astroalign.register(img_i, img_ref)
                except Exception: img_reg = img_i
                else: pass

                # # MATCH COORDINATES AND SHIFT IMAGES:
                # if img_reg is False:
                #     # Use star_finder to find stellar coordinates:
                #     self.star_finder(img_i, sigma=self.starsigma)
                #     # First image is the reference:
                #     if i is 0:
                #         LF_shift = LF_i
                #         LF_0     = LF_i
                #         COF_0    = self.COF
                #         self.indices1 = 0
                #         self.indices2 = 0
                #         shift    = 0
                #     # And then match and shift consecutive frames:
                #     if i is not 0:
                #         self.match_coordinates(COF_0, self.COF, self.pixshift)
                #         shift    = np.mean(COF_0[self.indices1] - self.COF[self.indices2], axis=0) 
                #         LF_shift = snd.interpolation.shift(LF_i, shift)
                #     # PLOT IMAGES:
                #     if self.plot[2] is True:    
                #         self.FITS_shift(LF_i, COF_0, self.COF, self.radius, self.nstars, \
                #                         self.indices1, self.indices2, shift, self.notdate[i], \
                #                         self.LF_filt[i], i)
                
                #SAVE IMAGE:
                fits.writeto(string_i, img_reg, header=hduls[0].header, overwrite=True)
                
            # Print to bash:
            self.compilation(i, self.LF_n, 'Reduced')
        print; print('')

        
    def star_finder(self, pixel_array, min_pix=7, sigma=3):       
        """
        Function to find the coordinates of the stars in the image using a threshold "sigma" and
        the minimum number of pixels above the threshold ("min_pix") for identification. It returns
        the Center Of Flux (COF) in (x,y) coordinate space, the approx radius in pixels of each star,
        and the number of stars detected.
        """
        # Height and width:
        h, w = np.shape(pixel_array)
        # FIND CENTER OF FLUX FOR STARS ABOVE THRESHOLD:
        # Define threshold as a number of standard deviations above the mean:
        threshold = np.mean(pixel_array) + sigma*np.std(pixel_array)
        # Find all pixels above the threshold:
        above_threshold = np.where(pixel_array > threshold, 1, 0)
        # Label the structures (where starmap = 1 that are adjacent to others):
        labels, N_stars = snd.label(above_threshold, structure = np.ones((3,3)))
        # Sum the number of elements in each structure:
        sums = snd.sum(above_threshold, labels, range(1,N_stars+1))
        # Choose only structures with more than min_pix elements (+1 index mismatch):
        stars = np.where(sums > min_pix)[0] + 1
        # Define starmap as 0 where there are no stars and 1 where there are stars:
        starmap = np.zeros(np.shape(pixel_array))
        for star in stars: starmap = starmap + np.where(labels == star, 1, 0)
        # Label all the structures again:
        labels, N_stars = snd.label(starmap, structure = np.ones((3,3)))
        # Find the center of mass of all the stars found above
        COF = snd.center_of_mass(pixel_array, labels, range(1,N_stars+1))
        # Estimate the radius of the star in pixels and save parameters:
        self.radius = np.sqrt(sums[stars-1]/np.pi)    
        self.COF    = np.asarray(COF)
        self.nstars = N_stars
        
    
    def match_coordinates(self, array1, array2, threshold=20):
        """
        This function match two set of coordinates by finding the minimum distance from i'th array1 
        star to every other array2 star. To do so it needs a threshold of how many pixels it should
        look for a match in coordinate space. The utility returns row indices with all indices mathing
        in each array. A plot can be optionally made using "plot==1"
        """
        value_min = np.zeros(len(array1))
        index_min = {}
        # FIND MINIMUM DISTANCE WITH PYTHAGOREAN GEOMETRY: 
        for i in range(len(array1)):
            d = np.sqrt( (array2[:,0]-array1[i,0])**2 + (array2[:,1]-array1[i,1])**2 )
            index_min[i] = np.argmin(d)
            value_min[i] = d[index_min[i]]
        # array1 indices of all stars:
        index_min = list(index_min.values())
        # find array1 stars within threshold:
        self.indices1 = np.where(value_min<threshold)[0]
        # Final list of matching array2 stars:
        self.indices2 = [index_min[i] for i in self.indices1]

    #============================================================================================#
    #                                         RGB COMBINE                                        #
    #============================================================================================#

    def rgb_combine(self): 
        """
        This function takes RGB images and combie them to one sigle color image. All images are
        aligned before combined. The best result is obtained by performing image reduction (with
        flats, and darks) before using this function.
        """
        # LOAD FILES:
        LF_files = np.sort(glob.glob('{}imreg*'.format(self.path)))
        LF_hduls = np.array([fits.open(str(files)) for files in LF_files])
        LF_i     = np.array([LF_hduls[i][0].data for i in range(self.LF_n)])
        
        # COMBINE IMAGES OF THE SAME FILTER:
        LF_dif      = np.unique(self.LF_filt)
        LF_filt_dif = np.array([np.where(self.LF_filt==LF_dif[i])[0] for i in range(len(LF_dif))])
        images = np.zeros((len(LF_dif), self.h, self.w))
        for i in range(len(LF_dif)):
            for j in range(len(LF_filt_dif[i])):
                images[i] += LF_i[LF_filt_dif[i][j]]  
            images[i] = images[i]/np.max(images[i])

        # CONSTRUCT 3D CUBE OF LIGHT FRAMES:
        im = np.copy(images)
        R = images[1]
        G = images[2]
        B = images[0]
        ds   = 2
        # Combining colors:
        img = np.zeros((self.h, self.w, 3))
        img[:,:,0] = self.linear(R, ds)
        img[:,:,1] = self.linear(G, ds)
        img[:,:,2] = self.linear(B, ds)
        # Rotate image so it corresponds to the fits:
        img = np.flipud(img)
        # Crop corners to remove color:
        pix = 10
        img = img[pix:self.h-pix-pix, pix:self.w-pix, :]

        #self.FITS(images[2])
        #print(LF_dif)
        #fits.writeto('{}hej.fits'.format(self.path), images[1])
        #sys.exit()

        # SAVE FINAL IMAGES:
        plt.imsave('{}color_{}.png'.format(self.path, self.target), img)
        for i in range(len(images)):
            fits.writeto('{}final_{}.fits'.format(self.path, LF_dif[i]), images[i], overwrite=True)
        
        # PLOT A SCALED COLOR IMAGE: 
        #if self.plot[3] is True:
        self.FITS_color(img)

    #---------------------------------------------------------------------------------------#
    #                                       PLOT TOOLS                                      #
    #---------------------------------------------------------------------------------------# 
    
    def compilation(self, i, i_max, text=''):
        """ This function print out a compilation time menu-bar in the terminal.""" 
        percent = (i + 1) / (i_max * 1.0) * 100
        # print int(percent/2), 50-int(percent/2)
        # We here divide by 2 as the length of the bar is only 50 characters:
        bar = "[" + "-" * int(percent/2) + '>' + " " *(50-int(percent/2))+"] {}% {}".format(int(percent),\
                                                                                            text)
        sys.stdout.write(u"\u001b[1000D" +  bar)
        sys.stdout.flush()

    def FITS(self, img, sigma=2):
        plt.figure()
        plt.imshow(self.linear(img, sigma), cmap='Greys', origin='lower')
        plt.show()

    def FITS_calib(self, img1, img2, date, filt, sigma=2):
        filt = str(filt).replace('_', ' ')
        fig, (ax1, ax2) = plt.subplots(1, 2)
        ax1.imshow(self.linear(img1, sigma), cmap='Greys', origin='lower')
        ax2.imshow(self.linear(img2, sigma), cmap='Greys', origin='lower')
        fig.suptitle('Image Reduction \n {} - {}'.format(date, filt))
        ax1.set_title('Before')
        ax2.set_title('After')
        plt.show()

    def FITS_clean(self, img1, img2, date, filt, mask, sigma=2):
        filt = str(filt).replace('_', ' ')
        radius, COF = self.find_structures(self.mask)
        print(COF)
        fig, (ax1, ax2) = plt.subplots(1, 2)    
        ax1.scatter(COF[:,1], COF[:,0], s=10*radius, facecolors='none', edgecolors='r')
        ax1.imshow(self.linear(img1, sigma), cmap='Greys', origin='lower')
        ax2.imshow(self.linear(img2, sigma), cmap='Greys', origin='lower')
        fig.suptitle('Cosmic Removals \n {} - {}'.format(date, filt))
        ax1.set_title('Before')
        ax2.set_title('After')
        plt.show()

    def FITS_shift(self, img, COF_0, COF_i, radius, nstars, indices1, indices2, \
                   shift, date, filt, i, sigma=2):
        filt = str(filt).replace('_', ' ')
        plt.figure()
        plt.imshow(self.linear(img, sigma), cmap='Greys', origin='lower')
        if i is 0:
            plt.title('Shift Images (TEMPLATE) \n {} - {} \n Identified {} stars'.\
                      format(date, filt, nstars))
            plt.scatter(COF_0[:,1], COF_0[:,0], s=radius*5, marker='o', facecolors='none', edgecolors='r')
        if i is not 0:    
            plt.scatter(COF_0[:,1], COF_0[:,0], marker='o', facecolors='none', edgecolors='r')
            plt.scatter(COF_i[:,1], COF_i[:,0], marker='o', facecolors='none', edgecolors='b')
            plt.scatter(COF_i[:,1][indices2], COF_i[:,0][indices2], marker='x', facecolors='w')
            plt.title('Shift Images \n {} - {} \n Shifts in (x, y) = ({:.2f}, {:.2f}) pixels '.\
                      format(date, filt, shift[1], shift[0]))
        plt.xlabel('x (pixels)'); plt.ylabel('y (pixels)')
        plt.show()

    def FITS_color(self, img):
        pylab.clf()
        pylab.imshow(img, aspect='equal')
        pylab.title('{}'.format(self.target))
        pylab.show()
        
    def linear(self, img, sigma):
        """ Performs linear scaling of the input np array. """
        img_min, img_max = img.mean()-sigma*img.std(), img.mean()+sigma*img.std()
        imageData = np.array(img, copy=True)
        imageData = imageData.clip(min=img_min, max=img_max)
        imageData = (imageData - img_min) / (img_max - img_min)
        indices = np.where(imageData < 0)
        imageData[indices] = 0.0
        indices = np.where(imageData > 1)
        imageData[indices] = 1.0
        return imageData

##############################################################################################
#                                     TOP-LAYER PIPELINE                                     #
##############################################################################################

#--------------------------------------------------------------#
#                PARSING COMMAND-LINE ARGUMENTS                #
#--------------------------------------------------------------#

# Initialize input parameters:
argm = 7             # Max number of arguments parsed
argv = sys.argv      # Arguments parsed to pipeline
argc = len(argv)     # Number of arguments parsed to pipeline
# Help usage function:
def help():
    print(Fore.BLUE+Style.BRIGHT+"""Usage : %s [-p] [-r] [-s] [-c <clip>] </path/to/data/>
      ----------------------------------------------------------
    -p: plot option - Plots the result of each reduction step
    -r: redo option - Redo the entire calibration
    -s: skip option - Skip flat-fielding, e.g. if no flats are available
    -c: clip option - Select sensitivity of cosmic detection; clip=[0.1-2.0]"""% \
    argv[0][2:]+Style.RESET_ALL)
# Print usage if no arguments are given:
if argc==1: help(); sys.exit()
# Check for obvious wrong parsing with a path/to/data:
if argc>argm+1 or \
   argc==2 and len(argv[1])==2 or \
   argc==3 and len(argv[2])==2 or \
   argc==4 and len(argv[3])==2 or \
   argc==5 and len(argv[4])==2 or \
   argc==6 and len(argv[5])==2 or \
   argc==7 and len(argv[6])==2:
   print(Fore.RED+Style.BRIGHT+'[ERROR]: Wrong input!'+Style.RESET_ALL)
   help(); sys.exit()
# Check parsed optional arguments:
try:
    opts, args = getopt.getopt(argv[1:], 'prscb')
except getopt.error:
    sys.stdout = sys.stderr
    print(Fore.RED+Style.BRIGHT+'[ERROR]: Wrong input!'+Style.RESET_ALL)
    help(); sys.exit()
for opt, arg in opts:
    # Parsing True argument:
    if opt == '-p': plot = True
    if opt == '-r': redo = True
    if opt == '-s': skip = True
    if opt == '-c': clip = True
    if opt == '-b': bord = True
# Checking plot argument:
try: plot
except NameError: plot = False
else: pass 
# Checking redo argument:
try: redo
except NameError: redo = False
else: pass
# Checking skip argument:
try: skip
except NameError: skip = False
else: pass
# Checking cosmic detection limit or set to default:
try: clip
except NameError: clip = 0.5                 
else:
    if argc==4: clip = argv[2]
    if argc==5: clip = argv[3]
    if argc==6: clip = argv[4]
    if argc==7: clip = argv[5]
# Parsing the path:
if argc==2: path = argv[1]
if argc==3: path = argv[2]
if argc==4: path = argv[3]
if argc==5: path = argv[4]
if argc==6: path = argv[5]
if argc==7: path = argv[6]

#--------------------------------------------------------------#
#                EXECUTING AND WRTING TO BASH                  #
#--------------------------------------------------------------#

print(Back.BLUE+Style.BRIGHT+\
      '                                                                             '+Style.RESET_ALL)
print(Back.BLUE+Style.BRIGHT+\
      '         __/\__                  NOTAstrophot                  __/\__        '+Style.RESET_ALL)
print(Back.BLUE+Style.BRIGHT+\
      '         \    /                  ------------                  \    /        '+Style.RESET_ALL)
print(Back.BLUE+Style.BRIGHT+\
      '         /_  _\       Astrophography Software for ALFOSC       /_  _\        '+Style.RESET_ALL)
print(Back.BLUE+Style.BRIGHT+\
      '           \/              NORDIC OPTICAL TELESCOPE              \/          '+Style.RESET_ALL)
print(Back.BLUE+Style.BRIGHT+\
      '                                                                             '+Style.RESET_ALL)
# IMPORT CLASS AND FUNCTIONS:
n = NOTAstrophot(plot, redo, skip, clip, path)
# Show diagram of files that is going to be reduced:
os.system('notheader %sAL*'% path)
#-----------------
# IMAGE REDUCTION:
#-----------------
step1 = glob.glob('{}calib*'.format(path))
if step1!=[] and redo==False:
    print(Fore.GREEN+'1/4: IMAGE REDUCTION: Reduced images already exist - Skipping step')
if step1==[] or redo==True:
    print(Fore.GREEN+Style.BRIGHT+'1/4: IMAGE REDUCTION: Loading images..'+Style.RESET_ALL)
    n.image_reduction()    
    if skip==True:
        print(Fore.YELLOW+'     Skipping image reduction (not recommended!)'+Style.RESET_ALL)
#-----------------
# COSMICS REMOVAL:
#-----------------
step2 = glob.glob('{}clean*'.format(path))
if step2!=[] and redo==False:
    print(Fore.GREEN+'2/4: COSMICS REMOVAL: Cleaned images already exist - Skipping step')
if step2==[] or redo==True:
    print(Fore.GREEN+Style.BRIGHT+'2/4: COSMICS REMOVAL: This might take a while..'+Style.RESET_ALL)
    n.cosmic_removal()   
#-----------------
# IMAGE ALIGNMENT:
#-----------------
step3 = glob.glob('{}imreg*'.format(path))
if step3!=[] and redo==False:
    print(Fore.GREEN+'3/4: IMAGE REGISTRATION: Aligned images already exist - Skipping step')
if step3==[] or redo==True:
    print(Fore.GREEN+Style.BRIGHT+'3/4: IMAGE REGISTRATION: Aligning images..'\
          +Style.RESET_ALL)
    n.image_alignment()
#-----------------
#  COLOR IMAGE  :
#-----------------
print(Fore.GREEN+Style.BRIGHT+'4/4: COMBINING IMAGES AND MAKING COLOR IMAGE'+Style.RESET_ALL)
n.rgb_combine()
print(Back.BLUE+Style.BRIGHT+\
      '                                FINITO!                               '+Style.RESET_ALL)
